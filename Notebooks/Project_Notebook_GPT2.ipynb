{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Notebook - GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrNfVNueNhR"
      },
      "source": [
        "# COVID-19 Doctor Chatbot - GPT2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onU41i8g1J3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfdf822-19c6-42f9-81fb-323d6b870789"
      },
      "source": [
        "!pip -q install transformers\n",
        "!pip install gdown\n",
        "!pip install \"nltk==3.4.5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 50.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLaJbr59BlYA"
      },
      "source": [
        "## Set up drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRIAywQT3eWR",
        "outputId": "70e67ff8-d050-493a-a404-d3998c02f839"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1-Cmprk6ZOvSrOCxoZldu-qCXuPGyFjtz"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Cmprk6ZOvSrOCxoZldu-qCXuPGyFjtz\n",
            "To: /content/drive/MyDrive/Colab/GPT2-finetune/pytorch_model.bin\n",
            "510MB [00:02, 178MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svLYe9LO4Nma"
      },
      "source": [
        "!mv pytorch_model.bin output-small-save/"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1155nQJ_GShb"
      },
      "source": [
        "## Dataset setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvfZN6fO48x2"
      },
      "source": [
        "Set up dataset and view first 5 items in training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHlJ6eE1mmpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0296171-609f-4f36-e39f-d8132321fff7"
      },
      "source": [
        "import dataset\n",
        "\n",
        "df_trn, df_val = dataset.make_dataset(path_to_train_data=\"data/train_data.json\", path_to_validation_data=\"data/validate_data.json\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> /content/drive/My Drive/Colab/GPT2-finetune/dataset.py(12)make_dataset()\n",
            "-> f_validate.close()\n",
            "(Pdb) c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_Iv3O_nmDpqw",
        "outputId": "ad162d8d-0fba-4485-d22e-f4f3e2f4b7d9"
      },
      "source": [
        "df_trn.head(5)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello, I understand your concern. I just have ...</td>\n",
              "      <td>Hello doctor, I get a cough for the last few d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hello, I can understand your concern.In my opi...</td>\n",
              "      <td>Hello doctor, I am suffering from coughing, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hello. Anxiety can manifest itself in physical...</td>\n",
              "      <td>Hello doctor,I am a 23-year-old man. I have an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hello,please answer the following:Any travel h...</td>\n",
              "      <td>Hello doctor,Last night I was getting chills, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello and welcome to Ask A Doctor service.I ha...</td>\n",
              "      <td>Hi, I am Chaitanya, 27 years old. I use to swi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            response                                            context\n",
              "0  Hello, I understand your concern. I just have ...  Hello doctor, I get a cough for the last few d...\n",
              "1  Hello, I can understand your concern.In my opi...  Hello doctor, I am suffering from coughing, th...\n",
              "2  Hello. Anxiety can manifest itself in physical...  Hello doctor,I am a 23-year-old man. I have an...\n",
              "3  Hello,please answer the following:Any travel h...  Hello doctor,Last night I was getting chills, ...\n",
              "4  Hello and welcome to Ask A Doctor service.I ha...  Hi, I am Chaitanya, 27 years old. I use to swi..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KrbJd6_8nU0P",
        "outputId": "947476dd-a5df-407d-df11-593d0b05af49"
      },
      "source": [
        "df_val.head(5)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Corona-virus. At 33 you may not need testing. ...</td>\n",
              "      <td>I have a constant cough and my chest has now b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Less likely. Recommended to stay 6 feet apart....</td>\n",
              "      <td>If someone has carona virus and iam passing by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test   Please stay at home, rest, drink fluids...</td>\n",
              "      <td>I am concerned that I’m showing symptoms of co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Death. At your age the risk of death is the fo...</td>\n",
              "      <td>What are my chances of becoming seriously ill ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unknown but low   Based on current data it is ...</td>\n",
              "      <td>Nervous about coronavirus. I am 26 years old a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            response                                            context\n",
              "0  Corona-virus. At 33 you may not need testing. ...  I have a constant cough and my chest has now b...\n",
              "1  Less likely. Recommended to stay 6 feet apart....  If someone has carona virus and iam passing by...\n",
              "2  Test   Please stay at home, rest, drink fluids...  I am concerned that I’m showing symptoms of co...\n",
              "3  Death. At your age the risk of death is the fo...  What are my chances of becoming seriously ill ...\n",
              "4  Unknown but low   Based on current data it is ...  Nervous about coronavirus. I am 26 years old a..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkvMNnrnVHQw"
      },
      "source": [
        "## Evaluating\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E1haqp0nfXq",
        "outputId": "6f1b9328-de4f-450d-9d8d-2bbff5af8755"
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-04 22:00:10.930707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/04/2020 22:00:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n",
            "12/04/2020 22:00:23 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f959d6c1160>\n",
            "12/04/2020 22:00:23 - INFO - __main__ -   Evaluate the following checkpoints: ['output-small-save']\n",
            "12/04/2020 22:00:29 - INFO - utils -   Creating features from dataset file at cached\n",
            "12/04/2020 22:00:29 - INFO - utils -   Saving features into cached file cached/gpt2_cached_lm_512\n",
            "12/04/2020 22:00:29 - INFO - evaluate -   ***** Running evaluation  *****\n",
            "12/04/2020 22:00:29 - INFO - evaluate -     Num examples = 60\n",
            "12/04/2020 22:00:29 - INFO - evaluate -     Batch size = 4\n",
            "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=15.0, style=ProgressStyle(description_wi…\n",
            "\n",
            "12/04/2020 22:00:30 - INFO - evaluate -   ***** Eval results  *****\n",
            "12/04/2020 22:00:30 - INFO - evaluate -     perplexity = tensor(14.2759)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZV6fjS6xwMV"
      },
      "source": [
        "### Show up to 5 test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1DwhiKDJZVZ",
        "outputId": "43b59601-6105-48b1-ecf8-12fd7c6e9dc5"
      },
      "source": [
        "test_chatbot = []\n",
        "\n",
        "for i in range(5): #len(test_query)\n",
        "  tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "  model = AutoModelWithLMHead.from_pretrained('output-small-save')\n",
        "  # append the new user input tokens to the chat history\n",
        "  bot_input_ids = tokenizer.encode(test_query[i] + tokenizer.eos_token, return_tensors='pt')\n",
        "  print(\"User: {} \\n\".format(test_query[i]))\n",
        "\n",
        "  # generated a response while limiting the total chat history to 1000 tokens, \n",
        "  chat_history_ids = model.generate(\n",
        "      bot_input_ids, max_length=100,\n",
        "      pad_token_id=tokenizer.eos_token_id,  \n",
        "      no_repeat_ngram_size=3,       \n",
        "      do_sample=True, \n",
        "      top_k=10, \n",
        "      top_p=0.7,\n",
        "      temperature = 0.8\n",
        "  )\n",
        "\n",
        "  # pretty print last ouput tokens from bot\n",
        "  print(\"Chatbot: {} \\n\\n\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "  test_chatbot.append(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True))\n",
        "\n",
        "print(len(test_chatbot))\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User: I have all the symptoms except fever, I went to Medicross and Dr said I can get tested if I want to I'm not sure if I should. She gave me antibiotics Klacid XL 500mg, she said I can take it if I feel worse I'm worried it will make immune system bad? \n",
            "\n",
            "Chatbot: Take a test.    You will likely need to take the test. \n",
            "\n",
            "\n",
            "User: I have pain/discomfort in my lungs. I don't experience simultaneous on both lungs and it not always at the hame position. I don't have a head nor do I have high temperature. I sneeze and cough maybe once a day. Do I have corona, should I get tested? \n",
            "\n",
            "Chatbot: I can understand your concern. I have no idea what you are experiencing. If you have a cold or other respiratory disease, consult your local physician. \n",
            "\n",
            "\n",
            "User: I travelled to Mauritius and do not have symptoms. Should I get tested for covid19? \n",
            "\n",
            "Chatbot: Yes, if you are in contact with someone with Covid19. You should be tested for Covid 19.    If you have a fever and or fever, get tested and get tested.  Would you like to video or text chat with me? \n",
            "\n",
            "\n",
            "User: I have a dry cough and a sore throat. I do not have a fever and a slight headache (could be I need more water) I am 4 months pregnant and not sure If I should be tested for Corona? \n",
            "\n",
            "Chatbot: No need to worry. If you have a cough and have a sore nose, then you should be fine. If your fever is high, you should also be tested. \n",
            "\n",
            "\n",
            "User: I went to the Dr for a cough and fever on march 5. They diagnosed me with bronchitis. I was not doing any better, so I returned to the Dr on march 15. They sent me to the ER to get tested for covid. At the er they ran a number of tests including a covid t. \n",
            "\n",
            "Chatbot: I can understand your concern. However, the symptoms are very similar to pneumonia. If you are having a fever, cough or other such thing, then you should \n",
            "\n",
            "\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40rKH7FxJaHM"
      },
      "source": [
        "## Generate test results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_wcWTNKMfW3"
      },
      "source": [
        "with open('gpt2-results.txt') as f:\n",
        "    test_chatbot = f.readlines()\n",
        "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
        "test_chatbot = [x.strip() for x in content] "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnV2P6PpWNUi"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_6uMEd6WcLe"
      },
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.nist_score import sentence_nist"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZfpaUPaffzr",
        "outputId": "046df779-c641-4baf-8437-e45caedf29c7"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuv4nCbpWhmo"
      },
      "source": [
        "import metrics\n",
        "bleu_2, bleu_4, meteor, nist_2, nist_4 = metrics.get_metrics(test_chatbot, test_response)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p59t0xOPfwLB",
        "outputId": "02a46725-4916-4187-9035-4e0c426e9a35"
      },
      "source": [
        " bleu_2, bleu_4, meteor, nist_2, nist_4"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1987791535170549,\n",
              " 0.10355670162282384,\n",
              " 0.22840520757502006,\n",
              " 0.9900288417339577,\n",
              " 1.0254752183668514)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eDkPEuvbD47"
      },
      "source": [
        "## Interactive Chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVqotI05gOS"
      },
      "source": [
        "A variety of methods can be used in responces generation. You can find more details about these methods by this [link](https://huggingface.co/blog/how-to-generate). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeqMwZktv7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504d2492-9b1d-44b4-8c22-643a34cc477c"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "model = AutoModelWithLMHead.from_pretrained('output-small-save')\n",
        "\n",
        "# Let's chat for 1 line\n",
        "for step in range(1):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    # print(new_user_input_ids)\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=100,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=10, \n",
        "        top_p=0.7,\n",
        "        temperature = 0.8\n",
        "    )\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"Chatbot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> User:Hi I am 39 years old and returned from Germany 19 days ago. Yesterday I started getting a sore throat, runny nose. Today I have sinus pressure and a headache with a blocked nose, throat seems to be improving. Should I get tested. If so how?\n",
            "Chatbot: Hello,    If you have a sore nose, you should definitely get tested for COVID-19.   Would you like to video or text chat with me?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}