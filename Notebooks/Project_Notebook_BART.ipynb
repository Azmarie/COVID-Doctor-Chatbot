{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training BART with Google Colab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code was trained in Colab\n",
    "!pip install simpletransformers -q\n",
    "!pip install nltk==3.4.5\n",
    "\n",
    "import nltk\n",
    "print(nltk.__version__)\n",
    "\n",
    "try:\n",
    "  from nltk.translate.meteor_score import meteor_score\n",
    "  print('Meteor score will not work without the right ntlk version')\n",
    "except ImportError:\n",
    "  print('Still import issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import spacy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from simpletransformers.seq2seq import Seq2SeqModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.nist_score import sentence_nist\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('good to go')\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "csv_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/dialogue.csv' #original\n",
    "augmented_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/augmented.csv' #augmented version\n",
    "txt_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/covid_additional.txt' # raw text version\n",
    "\n",
    "dataset = pd.read_csv(augmented_link, names = ['input_text', 'target_text'], header=0)\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2)\n",
    "valid_df, test_df = train_test_split(test_df, test_size=0.5)\n",
    "\n",
    "print('The length of train_df is: ', len(train_df))\n",
    "print('The length of valid is: ', len(valid_df))\n",
    "print('The length of test_df is: ', len(test_df))\n",
    "\n",
    "\n",
    "def txt_to_dict(txt_path, save_path):\n",
    "\n",
    "    patient = []\n",
    "    doctor = []\n",
    "\n",
    "    with open(txt_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('Patient:'): \n",
    "                patient.append(' '.join(lines[i+1:i+2]))\n",
    "            \n",
    "            elif line.startswith('Doctor:'):\n",
    "                doctor.append(' '.join(lines[i+1: i+2]))\n",
    "\n",
    "    data = {'src': patient, 'trg': doctor}\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"max_seq_length\": 50,\n",
    "    \"train_batch_size\": 4, # check if we can have bigger weights. \n",
    "    \"eval_batch_size\": 1,\n",
    "    \"output_dir\": 'weights',\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"evaluate_generated_text\": True,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    \"use_multiprocessing\": True,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_length\": 50,\n",
    "    \"manual_seed\": 4,\n",
    "}\n",
    "\n",
    "\n",
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type=\"bart\",\n",
    "    encoder_decoder_name=\"facebook/bart-large\",\n",
    "    args=model_args,\n",
    ")\n",
    "\n",
    "\n",
    "model.train_model(train_df, eval_data=valid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(labels, preds):\n",
    "\n",
    "  for prediction in preds:\n",
    "    with open('prediction.txt', 'a') as f:\n",
    "      f.write(prediction + '\\n')\n",
    "\n",
    "  print('complete')\n",
    "\n",
    "\n",
    "\n",
    "print(model.eval_model(test_df, save = save_prediction))\n",
    "\n",
    "\"\"\"\n",
    "Predictions on a random string\n",
    "\"\"\"\n",
    "\n",
    "test = \"Hi doctor, What are the symptoms of Covid-19..?\"\n",
    "inference = model.predict([test])\n",
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The code crashes when I evaluate within the evalulate function. \n",
    "-This is an alternative\n",
    "\"\"\"\n",
    "\n",
    "def nist_2(labels, preds):\n",
    "\n",
    "    label = ' '.join([str(elem) for elem in labels])\n",
    "    prediction = ' '.join([str(elem) for elem in preds])\n",
    "  \n",
    "    if len(prediction) < 2 or len(label) < 2:\n",
    "        return 0\n",
    "    return sentence_nist([label], prediction, 2)\n",
    "\n",
    "def nist_4(labels, preds):\n",
    "\n",
    "    label = ' '.join([str(elem) for elem in labels])\n",
    "    prediction = ' '.join([str(elem) for elem in preds])\n",
    "\n",
    "    if len(prediction) < 4 or len(label) < 4:\n",
    "        return 0\n",
    "\n",
    "    return sentence_nist([label], prediction, 4)\n",
    "\n",
    "def calculate_m_score(target, predictions, length):\n",
    "\n",
    "  score = 0\n",
    "\n",
    "  for t, p in zip(target, predictions):\n",
    "    score += meteor_score(t, p)\n",
    "\n",
    "  \n",
    "  return score / length\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with open('prediction.txt') as fp:\n",
    "  line = fp.readline()\n",
    "  line = line.strip()\n",
    "  \n",
    "  while line:\n",
    "    if len(line) > 1:\n",
    "      predictions.append(line)\n",
    "    line = fp.readline()\n",
    "\n",
    "# label = ' '.join([str(elem) for elem in labels])\n",
    "pred = ' '.join([str(elem) for elem in predictions])\n",
    "target = test_df.target_text\n",
    "\n",
    "bleu2 = sentence_bleu(target, pred, weights=tuple(1 / 2 for i in range(2)))\n",
    "bleu4 = sentence_bleu(target, pred, weights=tuple(1 / 4 for i in range(2)))\n",
    "nist2 = nist_2(target, pred)\n",
    "nist4 = nist_4(target, pred)\n",
    "\n",
    "\n",
    "print('bleu2 is {}'.format(bleu2))\n",
    "print('bleu4 is {}'.format(bleu4))\n",
    "print('nist2 is {}'.format(nist2))\n",
    "print('nist4 is {}'.format(nist4))\n",
    "\n",
    "meteor = calculate_m_score(target, predictions, 71)\n",
    "\n",
    "print('meteor is {}'.format(meteor))"
   ]
  }
 ]
}