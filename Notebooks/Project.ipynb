{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_Pj8RlnJ8YpG"},"source":["### Install required packages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbXuVX1fyhGm","executionInfo":{"status":"ok","timestamp":1607471882092,"user_tz":480,"elapsed":14097,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"ab277c21-ce85-418b-8ce3-c29cda2bf03b"},"source":["# install required packages\n","!pip -q install transformers\n","!pip install gdown\n","!pip install \"nltk==3.4.5\"\n","!pip install pytorch_pretrained_bert \n","!pip install fire"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n","\u001b[K     |████████████████████████████████| 890kB 28.9MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 22.3MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n","Collecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5) (1.15.0)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449905 sha256=886a580cfd9fe2315d21f3e9df82abab6975d6ef4f5869a2e9afcb8f21fd9925\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.4.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7KrNfVNueNhR"},"source":["# COVID-19 Doctor Chatbot - Transformer"]},{"cell_type":"markdown","metadata":{"id":"Kt-4_Ouw8i_n"},"source":["## Set up Drive "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDbeAcA3yhGo","executionInfo":{"status":"ok","timestamp":1607473231507,"user_tz":480,"elapsed":13560,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"ce153281-193d-43fc-aa67-16147414f249"},"source":["# transformer model\r\n","!gdown https://drive.google.com/uc?id=1YrV42EAxggTYPDqyG4OylXcZsICailSa\r\n","# saved weights\r\n","!gdown https://drive.google.com/uc?id=1Km0FXuWXGlSHTjVdTp2a51Up4U1iT7RH\r\n","# test data\r\n","!gdown https://drive.google.com/uc?id=1rZt4uAKvbjFOYE3lGlUeUm2GJtkH_7P7"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1YrV42EAxggTYPDqyG4OylXcZsICailSa\n","To: /content/transformers_model.py\n","100% 1.29k/1.29k [00:00<00:00, 2.03MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Km0FXuWXGlSHTjVdTp2a51Up4U1iT7RH\n","To: /content/best_model.pth\n","419MB [00:01, 216MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1rZt4uAKvbjFOYE3lGlUeUm2GJtkH_7P7\n","To: /content/test_data.pth\n","100% 1.07M/1.07M [00:00<00:00, 68.2MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3q5s4YJyhGo","executionInfo":{"status":"ok","timestamp":1607474209040,"user_tz":480,"elapsed":992,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"98031645-c383-47a8-d943-54d12f531916"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","import numpy as np\n","from transformers_model import transformers_model\n","from pytorch_pretrained_bert import BertTokenizer\n","\n","import fire\n","import json\n","from collections import defaultdict\n","\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.translate.nist_score import sentence_nist\n","from nltk.util import ngrams\n","\n","import nltk\n","nltk.download('wordnet')"],"execution_count":51,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"zINffZsH8uNB"},"source":["## Defined evaluation metrics"]},{"cell_type":"code","metadata":{"id":"Jz-5PngQyhGp","executionInfo":{"status":"ok","timestamp":1607473342902,"user_tz":480,"elapsed":509,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}}},"source":["def bleu(predict, target, n):\n","    return sentence_bleu([target], predict, weights=tuple(1 / n for i in range(n)))\n","\n","\n","def nist(predict, target, n):\n","    if len(predict) < n or len(target) < n:\n","        return 0\n","    return sentence_nist([target], predict, n)\n","\n","\n","def cal_entropy(generated):\n","    etp_score = [0.0, 0.0, 0.0, 0.0]\n","    div_score = [0.0, 0.0, 0.0, 0.0]\n","    counter = [defaultdict(int), defaultdict(int),\n","               defaultdict(int), defaultdict(int)]\n","    for gg in generated:\n","        g = gg.rstrip().split()\n","        for n in range(4):\n","            for idx in range(len(g)-n):\n","                ngram = ' '.join(g[idx:idx+n+1])\n","                counter[n][ngram] += 1\n","    for n in range(4):\n","        total = sum(counter[n].values()) + 1e-10\n","        for v in counter[n].values():\n","            etp_score[n] += - (v+0.0) / total * (np.log(v+0.0) - np.log(total))\n","        div_score[n] = (len(counter[n].values())+0.0) / total\n","    return etp_score, div_score\n","\n","\n","def cal_length(sentences):\n","    sen_length = [len(s.split()) for s in sentences]\n","    return np.mean(sen_length), np.var(sen_length)\n","\n","\n","def calculate_metrics(predict, reference):\n","    reference_len = len(reference)\n","    predict_len = len(predict)\n","\n","    #-------------------bleu----------\n","    bleu_2 = bleu(predict, reference, 2)\n","    bleu_4 = bleu(predict, reference, 4)\n","    #-------------------nist----------\n","    nist_2 = nist(predict, reference, 2)\n","    nist_4 = nist(predict, reference, 4)\n","    #-------------------meteor----------\n","    predict = \" \".join(predict)\n","    reference = \" \".join(reference)\n","    meteor_scores = meteor_score([reference], predict)\n","    return bleu_2, bleu_4, nist_2, nist_4, meteor_scores\n","\n","\n","def top_k_logits(logits, k):\n","    \"\"\"Mask logits so that only top-k logits remain\n","    \"\"\"\n","    values, _ = torch.topk(logits, k)\n","    min_values = values[:, -1].unsqueeze(1).repeat(1, logits.shape[-1])\n","    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n","\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdNb7plxyhGp","executionInfo":{"status":"ok","timestamp":1607473350121,"user_tz":480,"elapsed":376,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}}},"source":["top_k = 50\n","temperature = 1.0\n","decoder_path='best_model.pth'\n","gpu_id=0"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKf2DrRo80Ox"},"source":["## Load pre-trained model and test set\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvfaWTfzyhGq","executionInfo":{"status":"ok","timestamp":1607473370043,"user_tz":480,"elapsed":17993,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"33f2cf76-3eaa-4086-fb26-29c2107ff889"},"source":["# load model\n","print('load the model....')\n","device = torch.device(f\"cuda:{gpu_id}\")\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","model = transformers_model()\n","model.load_state_dict(torch.load(decoder_path))\n","\n","device = torch.device(f\"cuda:0\")\n","model.to(device)\n","model.eval()\n","\n","print('load success')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["load the model....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 1058185.04B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["load success\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GchTwsrQyhGq","executionInfo":{"status":"ok","timestamp":1607473379179,"user_tz":480,"elapsed":365,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}}},"source":["# load test data\n","test_data = torch.load(\"test_data.pth\")\n","test_dataset = TensorDataset(*test_data)\n","test_dataloader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=1)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8B_yna_W9Aw5"},"source":["## generate output samples"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tjfr-4NvyhGq","executionInfo":{"status":"ok","timestamp":1607474403780,"user_tz":480,"elapsed":52802,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"0bb3afab-8aa0-442e-8689-b503bf74c010"},"source":["# start generate samples\n","update_count = 0\n","\n","bleu_2scores = 0\n","bleu_4scores = 0\n","nist_2scores = 0\n","nist_4scores = 0\n","\n","meteor_scores = 0\n","sentences = []\n","print('start generating....')\n","\n","for batch in test_dataloader:\n","        with torch.no_grad():\n","            batch = [item.to(device) for item in batch]\n","            encoder_input, decoder_input, mask_encoder_input, _ = batch\n","            #past, _ = model.encoder(encoder_input, mask_encoder_input)\n","            past = model.encoder(encoder_input, mask_encoder_input)[0]\n","\n","            prev_pred = decoder_input[:, :1]\n","            sentence = prev_pred\n","\n","            # decoding loop\n","            for i in range(100):\n","              #logits, _ = model.decoder(sentence, encoder_hidden_states=past)\n","              logits = model.decoder(sentence, encoder_hidden_states=past)[0]\n","              logits = model.linear(logits)\n","              logits = logits[:, -1]\n","              logits = logits.squeeze(1) / temperature\n","              \n","              logits = top_k_logits(logits, k=top_k)\n","              probs = F.softmax(logits, dim=-1)\n","              prev_pred = torch.multinomial(probs, num_samples=1)\n","              sentence= torch.cat([sentence, prev_pred], dim=-1)\n","              if prev_pred[0][0] == 102:\n","                  break\n","\n","            predict = tokenizer.convert_ids_to_tokens(sentence[0].tolist())\n","\n","            encoder_input = encoder_input.squeeze(dim=0)\n","            encoder_input_num = (encoder_input != 0).sum()\n","            inputs = tokenizer.convert_ids_to_tokens(encoder_input[:encoder_input_num].tolist())\n","\n","            decoder_input = decoder_input.squeeze(dim=0)\n","            decoder_input_num = (decoder_input != 0).sum()\n","\n","            reference = tokenizer.convert_ids_to_tokens(decoder_input[:decoder_input_num].tolist())\n","            #print(calculate_metrics(predict[1:-1], reference[1:-1]))\n","            temp_bleu_2, temp_bleu_4, temp_nist_2, temp_nist_4, temp_meteor_scores = calculate_metrics(predict[1:-1], reference[1:-1])\n","            \n","\n","            bleu_2scores += temp_bleu_2\n","            bleu_4scores += temp_bleu_4\n","            nist_2scores += temp_nist_2\n","            nist_4scores += temp_nist_4\n","\n","            meteor_scores += temp_meteor_scores\n","            sentences.append(\" \".join(predict[1:-1]))\n","            \n","            # print some samples\n","            if update_count % 50 == 0:\n","                patient = ' '.join(inputs[1:-1])\n","                reference = ' '.join(reference[1:-1])\n","                predict = ' '.join(predict[1:-1])\n","                \n","                print('-'*20 + f\"example {update_count}\" + '-'*20)\n","                print(f\"Patient: {patient.replace(' ##','')}\")\n","                print(f\"Reference: {reference.replace(' ##','')}\")\n","                print(f\"Predict: {predict.replace(' ##','')}\")\n","            \n","            update_count += 1"],"execution_count":54,"outputs":[{"output_type":"stream","text":["start generating....\n","--------------------example 0--------------------\n","Patient: i have had mild chest pain for over a week . it now seems more persistent and pronounced . i don ' t have shortness of breath or any other covid - 19 symptoms , except some fatigue . i have been traveling a lot in high risk areas . should i get tested ?\n","Reference: brief opinion : yes i would advise screening due to your exposure . fever is very commonly associated with covid - 19 . stay at home , rest , drink fluids and monitor your temperature . arrange the testing which also may include a chest image with your pcp . since your have been traveling , a pulmonary embolism is another possible cause of your shortness of breath . would you like to video or text chat with me ?\n","Predict: brief opinion : and symptoms you are not no your .\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:523: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:523: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:523: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["--------------------example 50--------------------\n","Patient: will warm weather stop the outbreak of covid - 19 ?\n","Reference: it is not yet known whether weather and temperature affect the spread of covid - 19 . some other viruses , like those that cause the common cold and flu , spread more during cold weather months but that does not mean it is impossible to become sick with these viruses during other months . there is much more to learn about the transmissibility , severity , and other features associated with covid - 19 and investigations are ongoing .\n","Predict: brief opinion : the home and it . would you like to would you may so , fever video or a person with me ?\n","--------------------example 100--------------------\n","Patient: hello , i have a quesition for you . is it safe to use public transit ? [SEP] if you must use public transit , regularly and thoroughly wash your hands and avoid touching your face with unwashed hands . continue to distance yourself 2 metres ( 6 feet ) away from others when possible . if this cannot be achieved , you may choose to wear a non - medical mask or cloth mask . also if you can , try to use public transit at off peak times . [SEP] what about going for shopping ? would it be safe ?\n","Reference: if you are sick , stay home ! do not go shopping , take public transit , go to work or go to school . call 811 for health advice about how you are feeling and what to do next . consider only shopping once per week for essential supplies and use food delivery services or online shopping where available .\n","Predict: hello and and covid - 19 , cough , it is the treatment .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BN9ThNKlyhGr","executionInfo":{"status":"ok","timestamp":1607474429678,"user_tz":480,"elapsed":431,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"7f59af07-12a2-4edc-b237-1d00cf557187"},"source":["entro, dist = cal_entropy(sentences)\n","mean_len, var_len = cal_length(sentences)\n","print(f'avg: {mean_len}, var: {var_len}')\n","print(f'entro: {entro}')\n","print(f'dist: {dist}')\n","print(f'test bleu_2scores: {bleu_2scores / update_count}')\n","print(f'test bleu_4scores: {bleu_4scores / update_count}')\n","print(f'test nist_2scores: {nist_2scores / update_count}')\n","print(f'test nist_4scores: {nist_4scores / update_count}')\n","print(f'test meteor_scores: {meteor_scores / update_count}')"],"execution_count":55,"outputs":[{"output_type":"stream","text":["avg: 32.30827067669173, var: 367.38617219741076\n","entro: [4.1226581566545, 6.168883457345389, 7.250598482876699, 7.724759428687033]\n","dist: [0.03164998836397413, 0.2939481268011457, 0.6407839245844544, 0.8073370959466186]\n","test bleu_2scores: 0.02914540023222242\n","test bleu_4scores: 0.009063939642336982\n","test nist_2scores: 0.28146148716215974\n","test nist_4scores: 0.2809897102343668\n","test meteor_scores: 0.09932598001363399\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MMWlXJQhyhGs"},"source":["# COVID-19 Doctor Chatbot - GPT2\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dLaJbr59BlYA"},"source":["## Set up drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRIAywQT3eWR","executionInfo":{"status":"ok","timestamp":1607471955182,"user_tz":480,"elapsed":6630,"user":{"displayName":"chenhao wang","photoUrl":"","userId":"11824900318299348755"}},"outputId":"269209b2-065d-415a-82b1-102d51fd742a"},"source":["!gdown https://drive.google.com/uc?id=1-Cmprk6ZOvSrOCxoZldu-qCXuPGyFjtz"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1-Cmprk6ZOvSrOCxoZldu-qCXuPGyFjtz\n","To: /content/pytorch_model.bin\n","510MB [00:03, 147MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svLYe9LO4Nma"},"source":["!mv pytorch_model.bin output-small-save/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1155nQJ_GShb"},"source":["## Dataset setup"]},{"cell_type":"markdown","metadata":{"id":"rvfZN6fO48x2"},"source":["Set up dataset and view first 5 items in training and validation sets"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHlJ6eE1mmpG","outputId":"d0296171-609f-4f36-e39f-d8132321fff7"},"source":["import dataset\n","\n","df_trn, df_val = dataset.make_dataset(path_to_train_data=\"data/train_data.json\", path_to_validation_data=\"data/validate_data.json\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["> /content/drive/My Drive/Colab/GPT2-finetune/dataset.py(12)make_dataset()\n","-> f_validate.close()\n","(Pdb) c\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"_Iv3O_nmDpqw","outputId":"ad162d8d-0fba-4485-d22e-f4f3e2f4b7d9"},"source":["df_trn.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hello, I understand your concern. I just have ...</td>\n","      <td>Hello doctor, I get a cough for the last few d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hello, I can understand your concern.In my opi...</td>\n","      <td>Hello doctor, I am suffering from coughing, th...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hello. Anxiety can manifest itself in physical...</td>\n","      <td>Hello doctor,I am a 23-year-old man. I have an...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hello,please answer the following:Any travel h...</td>\n","      <td>Hello doctor,Last night I was getting chills, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hello and welcome to Ask A Doctor service.I ha...</td>\n","      <td>Hi, I am Chaitanya, 27 years old. I use to swi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            response                                            context\n","0  Hello, I understand your concern. I just have ...  Hello doctor, I get a cough for the last few d...\n","1  Hello, I can understand your concern.In my opi...  Hello doctor, I am suffering from coughing, th...\n","2  Hello. Anxiety can manifest itself in physical...  Hello doctor,I am a 23-year-old man. I have an...\n","3  Hello,please answer the following:Any travel h...  Hello doctor,Last night I was getting chills, ...\n","4  Hello and welcome to Ask A Doctor service.I ha...  Hi, I am Chaitanya, 27 years old. I use to swi..."]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"KrbJd6_8nU0P","outputId":"947476dd-a5df-407d-df11-593d0b05af49"},"source":["df_val.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Corona-virus. At 33 you may not need testing. ...</td>\n","      <td>I have a constant cough and my chest has now b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Less likely. Recommended to stay 6 feet apart....</td>\n","      <td>If someone has carona virus and iam passing by...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test   Please stay at home, rest, drink fluids...</td>\n","      <td>I am concerned that I’m showing symptoms of co...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Death. At your age the risk of death is the fo...</td>\n","      <td>What are my chances of becoming seriously ill ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Unknown but low   Based on current data it is ...</td>\n","      <td>Nervous about coronavirus. I am 26 years old a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            response                                            context\n","0  Corona-virus. At 33 you may not need testing. ...  I have a constant cough and my chest has now b...\n","1  Less likely. Recommended to stay 6 feet apart....  If someone has carona virus and iam passing by...\n","2  Test   Please stay at home, rest, drink fluids...  I am concerned that I’m showing symptoms of co...\n","3  Death. At your age the risk of death is the fo...  What are my chances of becoming seriously ill ...\n","4  Unknown but low   Based on current data it is ...  Nervous about coronavirus. I am 26 years old a..."]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"markdown","metadata":{"id":"pkvMNnrnVHQw"},"source":["## Evaluating\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1E1haqp0nfXq","outputId":"6f1b9328-de4f-450d-9d8d-2bbff5af8755"},"source":["!python main.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-12-04 22:00:10.930707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","12/04/2020 22:00:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","12/04/2020 22:00:23 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f959d6c1160>\n","12/04/2020 22:00:23 - INFO - __main__ -   Evaluate the following checkpoints: ['output-small-save']\n","12/04/2020 22:00:29 - INFO - utils -   Creating features from dataset file at cached\n","12/04/2020 22:00:29 - INFO - utils -   Saving features into cached file cached/gpt2_cached_lm_512\n","12/04/2020 22:00:29 - INFO - evaluate -   ***** Running evaluation  *****\n","12/04/2020 22:00:29 - INFO - evaluate -     Num examples = 60\n","12/04/2020 22:00:29 - INFO - evaluate -     Batch size = 4\n","HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=15.0, style=ProgressStyle(description_wi…\n","\n","12/04/2020 22:00:30 - INFO - evaluate -   ***** Eval results  *****\n","12/04/2020 22:00:30 - INFO - evaluate -     perplexity = tensor(14.2759)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fZV6fjS6xwMV"},"source":["### Show up to 5 test results"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1DwhiKDJZVZ","outputId":"43b59601-6105-48b1-ecf8-12fd7c6e9dc5"},"source":["test_chatbot = []\n","\n","for i in range(5): #len(test_query)\n","  tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n","  model = AutoModelWithLMHead.from_pretrained('output-small-save')\n","  # append the new user input tokens to the chat history\n","  bot_input_ids = tokenizer.encode(test_query[i] + tokenizer.eos_token, return_tensors='pt')\n","  print(\"User: {} \\n\".format(test_query[i]))\n","\n","  # generated a response while limiting the total chat history to 1000 tokens, \n","  chat_history_ids = model.generate(\n","      bot_input_ids, max_length=100,\n","      pad_token_id=tokenizer.eos_token_id,  \n","      no_repeat_ngram_size=3,       \n","      do_sample=True, \n","      top_k=10, \n","      top_p=0.7,\n","      temperature = 0.8\n","  )\n","\n","  # pretty print last ouput tokens from bot\n","  print(\"Chatbot: {} \\n\\n\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n","  test_chatbot.append(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True))\n","\n","print(len(test_chatbot))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["User: I have all the symptoms except fever, I went to Medicross and Dr said I can get tested if I want to I'm not sure if I should. She gave me antibiotics Klacid XL 500mg, she said I can take it if I feel worse I'm worried it will make immune system bad? \n","\n","Chatbot: Take a test.    You will likely need to take the test. \n","\n","\n","User: I have pain/discomfort in my lungs. I don't experience simultaneous on both lungs and it not always at the hame position. I don't have a head nor do I have high temperature. I sneeze and cough maybe once a day. Do I have corona, should I get tested? \n","\n","Chatbot: I can understand your concern. I have no idea what you are experiencing. If you have a cold or other respiratory disease, consult your local physician. \n","\n","\n","User: I travelled to Mauritius and do not have symptoms. Should I get tested for covid19? \n","\n","Chatbot: Yes, if you are in contact with someone with Covid19. You should be tested for Covid 19.    If you have a fever and or fever, get tested and get tested.  Would you like to video or text chat with me? \n","\n","\n","User: I have a dry cough and a sore throat. I do not have a fever and a slight headache (could be I need more water) I am 4 months pregnant and not sure If I should be tested for Corona? \n","\n","Chatbot: No need to worry. If you have a cough and have a sore nose, then you should be fine. If your fever is high, you should also be tested. \n","\n","\n","User: I went to the Dr for a cough and fever on march 5. They diagnosed me with bronchitis. I was not doing any better, so I returned to the Dr on march 15. They sent me to the ER to get tested for covid. At the er they ran a number of tests including a covid t. \n","\n","Chatbot: I can understand your concern. However, the symptoms are very similar to pneumonia. If you are having a fever, cough or other such thing, then you should \n","\n","\n","5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"40rKH7FxJaHM"},"source":["## Generate test results\n"]},{"cell_type":"code","metadata":{"id":"t_wcWTNKMfW3"},"source":["with open('gpt2-results.txt') as f:\n","    test_chatbot = f.readlines()\n","# you may also want to remove whitespace characters like `\\n` at the end of each line\n","test_chatbot = [x.strip() for x in content] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnV2P6PpWNUi"},"source":["## Metrics"]},{"cell_type":"code","metadata":{"id":"y_6uMEd6WcLe"},"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.translate.bleu_score import SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.translate.nist_score import sentence_nist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZfpaUPaffzr","outputId":"046df779-c641-4baf-8437-e45caedf29c7"},"source":["nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"cuv4nCbpWhmo"},"source":["import metrics\n","bleu_2, bleu_4, meteor, nist_2, nist_4 = metrics.get_metrics(test_chatbot, test_response)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p59t0xOPfwLB","outputId":"02a46725-4916-4187-9035-4e0c426e9a35"},"source":[" bleu_2, bleu_4, meteor, nist_2, nist_4"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.1987791535170549,\n"," 0.10355670162282384,\n"," 0.22840520757502006,\n"," 0.9900288417339577,\n"," 1.0254752183668514)"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"markdown","metadata":{"id":"6eDkPEuvbD47"},"source":["## Interactive Chat"]},{"cell_type":"markdown","metadata":{"id":"rjVqotI05gOS"},"source":["A variety of methods can be used in responces generation. You can find more details about these methods by this [link](https://huggingface.co/blog/how-to-generate). "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIeqMwZktv7N","outputId":"504d2492-9b1d-44b4-8c22-643a34cc477c"},"source":["tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n","model = AutoModelWithLMHead.from_pretrained('output-small-save')\n","\n","# Let's chat for 1 line\n","for step in range(1):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n","    # print(new_user_input_ids)\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(\n","        bot_input_ids, max_length=100,\n","        pad_token_id=tokenizer.eos_token_id,  \n","        no_repeat_ngram_size=3,       \n","        do_sample=True, \n","        top_k=10, \n","        top_p=0.7,\n","        temperature = 0.8\n","    )\n","    \n","    # pretty print last ouput tokens from bot\n","    print(\"Chatbot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/models/auto/modeling_auto.py:852: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":[">> User:Hi I am 39 years old and returned from Germany 19 days ago. Yesterday I started getting a sore throat, runny nose. Today I have sinus pressure and a headache with a blocked nose, throat seems to be improving. Should I get tested. If so how?\n","Chatbot: Hello,    If you have a sore nose, you should definitely get tested for COVID-19.   Would you like to video or text chat with me?\n"],"name":"stdout"}]},{"source":["# Training BART with Google Colab\n","\n","- This is our third and final model.\n","- It's using Hugging Face based code.\n","- There are over 400m parameters, so you are not going to be able to train it without using COLAB.\n","- Please ensure that you have nltk version above 3.2 "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install simpletransformers -q\n","!pip install nltk==3.4.5\n","\n","import nltk\n","print(nltk.__version__)\n","\n","try:\n","  from nltk.translate.meteor_score import meteor_score\n","  print('Meteor score will not work without the right ntlk version')\n","except ImportError:\n","  print('Still import issue')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","import spacy\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from simpletransformers.seq2seq import Seq2SeqModel\n","from sklearn.model_selection import train_test_split\n","import os\n","import os.path\n","import tensorflow as tf\n","import os\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.nist_score import sentence_nist\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('good to go')\n","print(f'Device: {DEVICE}')\n","\n","csv_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/dialogue.csv' #original\n","augmented_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/augmented.csv' #augmented version\n","txt_link = 'https://raw.githubusercontent.com/chophilip21/covid_dialogue/main/covid_additional.txt' # raw text version\n","\n","dataset = pd.read_csv(augmented_link, names = ['input_text', 'target_text'], header=0)\n","train_df, test_df = train_test_split(dataset, test_size=0.2)\n","valid_df, test_df = train_test_split(test_df, test_size=0.5)\n","\n","print('The length of train_df is: ', len(train_df))\n","print('The length of valid is: ', len(valid_df))\n","print('The length of test_df is: ', len(test_df))\n","\n","\n","def txt_to_dict(txt_path, save_path):\n","\n","    patient = []\n","    doctor = []\n","\n","    with open(txt_path, 'r') as f:\n","        lines = f.readlines()\n","\n","        for i, line in enumerate(lines):\n","            if line.startswith('Patient:'): \n","                patient.append(' '.join(lines[i+1:i+2]))\n","            \n","            elif line.startswith('Doctor:'):\n","                doctor.append(' '.join(lines[i+1: i+2]))\n","\n","    data = {'src': patient, 'trg': doctor}\n","\n","    return data\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_args = {\n","    \"reprocess_input_data\": True,\n","    \"overwrite_output_dir\": True,\n","    \"max_seq_length\": 50,\n","    \"train_batch_size\": 4, # check if we can have bigger weights. \n","    \"eval_batch_size\": 1,\n","    \"output_dir\": 'weights',\n","    \"num_train_epochs\": 5,\n","    \"save_eval_checkpoints\": False,\n","    \"save_model_every_epoch\": False,\n","    \"evaluate_during_training\": True,\n","    \"evaluate_generated_text\": True,\n","    \"evaluate_during_training_verbose\": True,\n","    \"use_multiprocessing\": True,\n","    \"gradient_accumulation_steps\": 1,\n","    \"max_length\": 50,\n","    \"manual_seed\": 4,\n","}\n","\n","\n","model = Seq2SeqModel(\n","    encoder_decoder_type=\"bart\",\n","    encoder_decoder_name=\"facebook/bart-large\",\n","    args=model_args,\n",")\n","\n","\n","model.train_model(train_df, eval_data=valid_df)\n","\n","def save_prediction(labels, preds):\n","\n","  for prediction in preds:\n","    with open('prediction.txt', 'a') as f:\n","      f.write(prediction + '\\n')\n","\n","  print('complete')\n","\n","\n","\n","print(model.eval_model(test_df, save = save_prediction))\n","\n","\"\"\"\n","Predictions on a random string\n","\"\"\"\n","\n","test = \"Hi doctor, What are the symptoms of Covid-19..?\"\n","inference = model.predict([test])\n","print(inference)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nltk.download('wordnet')\n","\n","\n","\"\"\"\n","The code crashes when I evaluate within the evalulate function. \n","-This is an alternative\n","\"\"\"\n","\n","def nist_2(labels, preds):\n","\n","    label = ' '.join([str(elem) for elem in labels])\n","    prediction = ' '.join([str(elem) for elem in preds])\n","  \n","    if len(prediction) < 2 or len(label) < 2:\n","        return 0\n","    return sentence_nist([label], prediction, 2)\n","\n","def nist_4(labels, preds):\n","\n","    label = ' '.join([str(elem) for elem in labels])\n","    prediction = ' '.join([str(elem) for elem in preds])\n","\n","    if len(prediction) < 4 or len(label) < 4:\n","        return 0\n","\n","    return sentence_nist([label], prediction, 4)\n","\n","def calculate_m_score(target, predictions, length):\n","\n","  score = 0\n","\n","  for t, p in zip(target, predictions):\n","    score += meteor_score(t, p)\n","\n","  \n","  return score / length\n","\n","\n","predictions = []\n","\n","with open('prediction.txt') as fp:\n","  line = fp.readline()\n","  line = line.strip()\n","  \n","  while line:\n","    if len(line) > 1:\n","      predictions.append(line)\n","    line = fp.readline()\n","\n","# label = ' '.join([str(elem) for elem in labels])\n","pred = ' '.join([str(elem) for elem in predictions])\n","target = test_df.target_text\n","\n","bleu2 = sentence_bleu(target, pred, weights=tuple(1 / 2 for i in range(2)))\n","bleu4 = sentence_bleu(target, pred, weights=tuple(1 / 4 for i in range(2)))\n","nist2 = nist_2(target, pred)\n","nist4 = nist_4(target, pred)\n","\n","\n","print('bleu2 is {}'.format(bleu2))\n","print('bleu4 is {}'.format(bleu4))\n","print('nist2 is {}'.format(nist2))\n","print('nist4 is {}'.format(nist4))\n","\n","meteor = calculate_m_score(target, predictions, 71)\n","\n","print('meteor is {}'.format(meteor))"]}]}